{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4ac441b1fc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0472bf67b2bf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpHn_W9EDC9p",
        "outputId": "c13d9510-274d-4dd2-babd-c7a27e504373",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll2PewTQm5c2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/eeg model/vsirazenzadnji.csv\",delimiter=' ',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWMabEiChgFu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X= dataset.iloc[:,:-1].values\n",
        "y= dataset.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auiRzY67RWRK",
        "outputId": "ac733548-6998-4fca-dd5d-827db90c308e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "index = pd.Index(y)\n",
        "index.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqD-pTxfh2Dt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1v1n379EPQY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hje8w3S1MHFN",
        "outputId": "20ba30ec-7838-4ea3-be3b-999bc08091fa",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tQYs5JBGi0z",
        "outputId": "71883c49-81cc-4eba-af1e-4a9f6beb4553",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
        "x = tf.keras.layers.Dense(64,activation=\"relu\")(inputs)\n",
        "x = tf.keras.layers.Dense(32,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(64,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(64,activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(64,activation=\"relu\")(x)\n",
        "outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "\n",
        "convnn = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "print(convnn.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f536515be229",
        "outputId": "05841c50-6096-4d38-a9e9-3cabc4ba677b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
        "\n",
        "expand_dims = tf.expand_dims(inputs, axis=2)\n",
        "\n",
        "gru = tf.keras.layers.GRU(256, return_sequences=True)(expand_dims)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(gru)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(5, activation='softmax')(flatten)\n",
        "\n",
        "\n",
        "recnn = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "print(recnn.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLqYtzWfjitq",
        "outputId": "c79393d7-bf26-4da7-da22-dd0e4bde6951",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "convnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = convnn.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "7UgdOAckAIr2",
        "outputId": "f33773b0-b2b1-4852-cc17-e72db5709660",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-RnmwP5-k9pZ"
      },
      "source": [
        "# Rezultat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSqINQt_H71o",
        "outputId": "697d2cfb-8aa3-4f9f-d31c-f340bd0392c9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_acc = convnn.evaluate(X_test, y_test, verbose =0)[1]\n",
        "print(\"Natančnost modela: {:.3f}%\".format(model_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx-XdA50IAy3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(list(map(lambda x: np.argmax(x) , model.predict(X_test))))\n",
        "label_dict = {\"Gnus\":0, \"strah\":1, \"žalost\":2 , \"nevtralno\":3, \"veselje\":4}\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "clr = classification_report(y_test, y_pred, target_names=label_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "Wy29-SDmMzyf",
        "outputId": "c147a43e-701f-4508-93fc-bfb497d0ee86",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,8))\n",
        "sns.heatmap(cm, annot= True, fmt=\"g\",cbar =False, cmap = \"Blues\")\n",
        "plt.xticks(np.arange(5)+0.5)\n",
        "plt.yticks(np.arange(5)+0.5)\n",
        "plt.xlabel(\"napovedano\")\n",
        "plt.ylabel(\"dejansko\")\n",
        "plt.title(\"tabela napačnih klasifikacij\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Classification Report:\\n----------------------\\n\", clr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dv7REYehESN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "testset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/eeg model/zadnji.csv\",delimiter=\" \", header=None)\n",
        "new_X = testset.iloc[:,:-1].values\n",
        "new_y = testset.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAGIer5sOEfq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "new_X = scaler.fit_transform(new_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9HHJhLPEKFC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_acc = convnn.evaluate(new_X, new_y, verbose =0)[1]\n",
        "print(\"Natančnost modela: {:.3f}%\".format(model_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "S4vGfiqZ6DJn",
        "outputId": "9722fc77-fdf4-4740-fe1e-8054b619766e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "testset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1GLwYXThb3E",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ynovi_pred = np.array(list(map(lambda x: np.argmax(x) , model.predict(new_X))))\n",
        "nov_cm = confusion_matrix(new_y,ynovi_pred)\n",
        "nov_clr = classification_report(new_y, ynovi_pred, target_names=label_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEA4GrVyhoi9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,8))\n",
        "sns.heatmap(cm, annot= True, fmt=\"g\",cbar =False, cmap = \"Blues\")\n",
        "plt.xticks(np.arange(5)+0.5, label_dict.keys())\n",
        "plt.yticks(np.arange(5)+0.5, label_dict.keys())\n",
        "plt.xlabel(\"napovedano\")\n",
        "plt.ylabel(\"dejansko\")\n",
        "plt.title(\"tabela napačnih klasifikacij za posameznika (16 participant)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report za posameznika:\\n----------------------\\n\", nov_clr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sVVoLcTXDA9u"
      },
      "source": [
        "##CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n0f4s9MC_Zf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 3\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
